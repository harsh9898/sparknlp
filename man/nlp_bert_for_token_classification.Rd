% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bert-for-token-classification.R
\name{nlp_bert_for_token_classification}
\alias{nlp_bert_for_token_classification}
\title{Spark NLP BertForTokenClassification}
\usage{
nlp_bert_for_token_classification(
  x,
  input_cols,
  output_col,
  batch_size = NULL,
  case_sensitive = NULL,
  max_sentence_length = NULL,
  uid = random_string("bert_for_token_classification_")
)
}
\arguments{
\item{x}{A \code{spark_connection}, \code{ml_pipeline}, or a \code{tbl_spark}.}

\item{input_cols}{Input columns. String array.}

\item{output_col}{Output column. String.}

\item{batch_size}{Size of every batch (Default depends on model).}

\item{case_sensitive}{Whether to ignore case in index lookups (Default depends on model)}

\item{max_sentence_length}{Max sentence length to process (Default: 128)}

\item{uid}{A character string used to uniquely identify the ML estimator.}
}
\value{
The object returned depends on the class of \code{x}.

\itemize{
\item \code{spark_connection}: When \code{x} is a \code{spark_connection}, the function returns an instance of a \code{ml_estimator} object. The object contains a pointer to
a Spark \code{Estimator} object and can be used to compose
\code{Pipeline} objects.

\item \code{ml_pipeline}: When \code{x} is a \code{ml_pipeline}, the function returns a \code{ml_pipeline} with
the NLP estimator appended to the pipeline.

\item \code{tbl_spark}: When \code{x} is a \code{tbl_spark}, an estimator is constructed then
immediately fit with the input \code{tbl_spark}, returning an NLP model.
}
}
\description{
BertForTokenClassification can load Bert Models with a token classification head on top
(a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.
See \url{https://nlp.johnsnowlabs.com/docs/en/transformers#bertfortokenclassification}
}
