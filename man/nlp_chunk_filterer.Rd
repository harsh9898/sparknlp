% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/chunk_filterer.R
\name{nlp_chunk_filterer}
\alias{nlp_chunk_filterer}
\title{Spark NLP ChunkFilterer}
\usage{
nlp_chunk_filterer(
  x,
  input_cols,
  output_col,
  criteria = NULL,
  white_list = NULL,
  regex = NULL,
  uid = random_string("chunk_filterer_")
)
}
\arguments{
\item{x}{A \code{spark_connection}, \code{ml_pipeline}, or a \code{tbl_spark}.}

\item{input_cols}{Input columns. String array.}

\item{output_col}{Output column. String.}

\item{criteria}{isin or regex}

\item{white_list}{If defined, list of entities to process.}

\item{regex}{If defined, list of entities to process.}

\item{uid}{A character string used to uniquely identify the ML estimator.}
}
\value{
The object returned depends on the class of \code{x}.

\itemize{
\item \code{spark_connection}: When \code{x} is a \code{spark_connection}, the function returns an instance of a \code{ml_estimator} object. The object contains a pointer to
a Spark \code{Estimator} object and can be used to compose
\code{Pipeline} objects.

\item \code{ml_pipeline}: When \code{x} is a \code{ml_pipeline}, the function returns a \code{ml_pipeline} with
the NLP estimator appended to the pipeline.

\item \code{tbl_spark}: When \code{x} is a \code{tbl_spark}, an estimator is constructed then
immediately fit with the input \code{tbl_spark}, returning an NLP model.
}
}
\description{
Spark ML transformer that will filter out named entities by some conditions
or predefined look-up lists, so that you can feed these entities to other
annotators like Assertion Status or Entity Resolvers. It can be used with
two criteria: isin and regex.
See \url{https://nlp.johnsnowlabs.com/docs/en/licensed_release_notes#2-chunkfilterer}
}
