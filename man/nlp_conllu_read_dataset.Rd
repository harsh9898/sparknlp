% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.R
\name{nlp_conllu_read_dataset}
\alias{nlp_conllu_read_dataset}
\title{Transform CoNLLU format text file to Spark dataframe}
\usage{
nlp_conllu_read_dataset(sc, path, read_as = NULL, explode_sentences = NULL)
}
\arguments{
\item{sc}{a Spark connection}

\item{path}{path to the file to read}

\item{read_as}{Can be LINE_BY_LINE or SPARK_DATASET, with options if latter is used (default LINE_BY_LINE)}
}
\description{
In order to train a Lemmatizer annotator, we need to get CoNLLU format data as a spark dataframe.
There is a component that does this for us: it reads a plain text file and transforms it to a spark dataset.
See \url{https://nlp.johnsnowlabs.com/docs/en/annotators#conllu-dataset}. All the function arguments have defaults.
See \url{https://nlp.johnsnowlabs.com/api/index.html#com.johnsnowlabs.nlp.training.CoNLLU} for the defaults.
}
