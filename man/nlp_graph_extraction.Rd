% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/graph-extraction.R
\name{nlp_graph_extraction}
\alias{nlp_graph_extraction}
\title{Spark NLP GraphExtraction}
\usage{
nlp_graph_extraction(
  x,
  input_cols,
  output_col,
  delimiter = NULL,
  dependency_parser_model = NULL,
  entity_types = NULL,
  explode_entities = NULL,
  include_edges = NULL,
  max_sentence_size = NULL,
  merge_entities = NULL,
  merge_entities_iob_format = NULL,
  min_sentence_size = NULL,
  pos_model = NULL,
  relationship_types = NULL,
  root_tokens = NULL,
  typed_dependency_parser_model = NULL,
  uid = random_string("graph_extraction_")
)
}
\arguments{
\item{x}{A \code{spark_connection}, \code{ml_pipeline}, or a \code{tbl_spark}.}

\item{input_cols}{Input columns. String array.}

\item{output_col}{Output column. String.}

\item{delimiter}{Delimiter symbol used for path output (Default: ",")}

\item{dependency_parser_model}{Coordinates (name, lang, remoteLoc) to a pretrained Dependency Parser model (Default: Array())}

\item{entity_types}{Find paths between a pair of entities (Default: Array())}

\item{explode_entities}{When set to true find paths between entities (Default: false)}

\item{include_edges}{Whether to include edges when building paths (Default: true)}

\item{max_sentence_size}{Maximum sentence size that the annotator will process (Default: 1000).}

\item{merge_entities}{Merge same neighboring entities as a single token (Default: false)}

\item{merge_entities_iob_format}{IOB format to apply when merging entities}

\item{min_sentence_size}{Minimum sentence size that the annotator will process (Default: 2).}

\item{pos_model}{Coordinates (name, lang, remoteLoc) to a pretrained POS model (Default: Array())}

\item{relationship_types}{Find paths between a pair of token and entity (Default: Array())}

\item{root_tokens}{Tokens to be consider as root to start traversing the paths (Default: Array()).}

\item{typed_dependency_parser_model}{Coordinates (name, lang, remoteLoc) to a pretrained Typed Dependency Parser model (Default: Array())}

\item{uid}{A character string used to uniquely identify the ML estimator.}
}
\value{
The object returned depends on the class of \code{x}.

\itemize{
\item \code{spark_connection}: When \code{x} is a \code{spark_connection}, the function returns an instance of a \code{ml_estimator} object. The object contains a pointer to
a Spark \code{Estimator} object and can be used to compose
\code{Pipeline} objects.

\item \code{ml_pipeline}: When \code{x} is a \code{ml_pipeline}, the function returns a \code{ml_pipeline} with
the NLP estimator appended to the pipeline.

\item \code{tbl_spark}: When \code{x} is a \code{tbl_spark}, an estimator is constructed then
immediately fit with the input \code{tbl_spark}, returning an NLP model.
}
}
\description{
Spark ML transformer that Extracts a dependency graph between entities.
The GraphExtraction class takes e.g. extracted entities from a NerDLModel and creates a dependency
tree which describes how the entities relate to each other. For that a triple store format is used.
Nodes represent the entities and the edges represent the relations between those entities. The
graph can then be used to find relevant relationships between words.
}
\details{
Both the DependencyParserModel and TypedDependencyParserModel need to be present in the pipeline. There are two ways to set them:\preformatted{Both Annotators are present in the pipeline already. The dependencies are taken implicitly from these two Annotators.
Setting setMergeEntities to true will download the default pretrained models for those two Annotators automatically.
 The specific models can also be set with setDependencyParserModel and setTypedDependencyParserModel:
}

See \url{https://nlp.johnsnowlabs.com/docs/en/annotators#graphextraction}
}
