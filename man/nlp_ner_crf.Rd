% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ner-crf.R
\name{nlp_ner_crf}
\alias{nlp_ner_crf}
\title{Spark NLP NerCrfApproach}
\usage{
nlp_ner_crf(
  x,
  input_cols,
  output_col,
  label_col = NULL,
  min_epochs = NULL,
  max_epochs = NULL,
  l2 = NULL,
  C0 = NULL,
  loss_eps = NULL,
  min_w = NULL,
  external_features_path = NULL,
  external_features_delimiter = NULL,
  external_features_read_as = "LINE_BY_LINE",
  external_features_options = list(format = "text"),
  entities = NULL,
  verbose = NULL,
  random_seed = NULL,
  uid = random_string("ner_crf_")
)
}
\arguments{
\item{x}{A \code{spark_connection}, \code{ml_pipeline}, or a \code{tbl_spark}.}

\item{input_cols}{Input columns. String array.}

\item{output_col}{Output column. String.}

\item{label_col}{If DatasetPath is not provided, this sequence of Annotation type of column should have labeled data per token}

\item{min_epochs}{Minimum number of epochs to train}

\item{max_epochs}{Maximum number of epochs to train}

\item{l2}{L2 regularization coefficient for CRF}

\item{C0}{c0 defines decay speed for gradient}

\item{loss_eps}{If epoch relative improvement lass than this value, training is stopped}

\item{min_w}{Features with less weights than this value will be filtered out}

\item{external_features_path}{Path to file or folder of line separated file}

\item{external_features_delimiter}{something like this: Volvo:ORG with such delimiter}

\item{external_features_read_as}{readAs LINE_BY_LINE or SPARK_DATASET}

\item{external_features_options}{named list of options passed to the latter.}

\item{entities}{Array of entities to recognize}

\item{verbose}{Verbosity level}

\item{random_seed}{random seed}

\item{uid}{A character string used to uniquely identify the ML estimator.}
}
\value{
The object returned depends on the class of \code{x}.

\itemize{
\item \code{spark_connection}: When \code{x} is a \code{spark_connection}, the function returns an instance of a \code{ml_estimator} object. The object contains a pointer to
a Spark \code{Estimator} object and can be used to compose
\code{Pipeline} objects.

\item \code{ml_pipeline}: When \code{x} is a \code{ml_pipeline}, the function returns a \code{ml_pipeline} with
the NLP estimator appended to the pipeline.

\item \code{tbl_spark}: When \code{x} is a \code{tbl_spark}, an estimator is constructed then
immediately fit with the input \code{tbl_spark}, returning an NLP model.
}
}
\description{
Spark ML estimator that allows for a generic model to be trained by utilizing a CRF machine learning algorithm.
Its train data (train_ner) is either a labeled or an external CoNLL 2003 IOB based spark dataset with Annotations
columns. Also the user has to provide word embeddings annotation column.
Optionally the user can provide an entity dictionary file for better accuracy.
See \url{https://nlp.johnsnowlabs.com/docs/en/annotators#ner-crf}
}
